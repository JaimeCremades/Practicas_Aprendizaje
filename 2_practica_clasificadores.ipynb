{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151917a3",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En esta práctica vamos a entrenar varios clasificadores sobre un mismo dataset, usando todos los algoritmos de clasificación que hemos visto hasta ahora e implementándolos usando las librerías adecuadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba06670",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "El dataset que usaremos es \"Breast Cancer Wisconsin (Diagnostic)\", disponible en [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
    "También está disponible directamente en `sklearn.datasets.load_breast_cancer()`.\n",
    "\n",
    "**Descripción del dataset**\n",
    "\n",
    "\n",
    "| Aspecto                 | Detalle                                                   |\n",
    "| ----------------------- | --------------------------------------------------------- |\n",
    "| **Tipo de problema**    | Clasificación binaria                                     |\n",
    "| **Objetivo**            | Diagnosticar si un tumor es *maligno* (1) o *benigno* (0) |\n",
    "| **Número de muestras**  | 569                                                       |\n",
    "| **Número de variables** | 30 características numéricas                              |\n",
    "| **Balance de clases**   | Moderadamente balanceado (~37% malignos, ~63% benignos)   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b0650",
   "metadata": {},
   "source": [
    "# Métrica\n",
    "\n",
    "Elige la métrica adecuada para evaluar tus modelos. Justifica tu respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ed6a6",
   "metadata": {},
   "source": [
    "El dataset no está perfectamente balanceada, por lo que accuracy puede inducir sesgos (un modelo que siempre predice “benigno” tendría ~63% de acierto).\n",
    "\n",
    "El AUC-ROC mide la capacidad discriminativa del modelo (qué tan bien separa positivos y negativos) independientemente del umbral, y es más informativa cuando las clases son desiguales.\n",
    "\n",
    "Es además aplicable y comparable entre modelos probabilísticos (Naïve Bayes, Regresión Logística, Redes Bayesianas) y no probabilísticos (CART)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ad56b",
   "metadata": {},
   "source": [
    "# 1. Cargar el dataset e importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9fba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "# Separar X e y\n",
    "#X = \n",
    "#y =        \n",
    "feature_names = data.feature_names\n",
    "target_names = data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83626ae8",
   "metadata": {},
   "source": [
    "Información detallada sobre el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d89a3c",
   "metadata": {},
   "source": [
    "Veamos cómo son las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.target_names)\n",
    "\n",
    "print(np.unique(data.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98c81b",
   "metadata": {},
   "source": [
    "Por lo tanto, este dataset no sigue la convención usual y tenemos que:\n",
    "\n",
    "0 -> 'malignant'\n",
    "\n",
    "1 -> 'benign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar como dataframe, con y en la columna llamada 'target'\n",
    "#df = \n",
    "\n",
    "#print(\"Clase (counts):\")\n",
    "#print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64843e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d827383",
   "metadata": {},
   "source": [
    "# 2. Análisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9705c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de algunas variables por clase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f671d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los pairplots posibles, segmentados por clase.\n",
    "# Usa Seaborn pairplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1616c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "print(df.describe().T[['mean', 'std', 'min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaciones entre las variables\n",
    "# Para calcular las correlaciones necesitas la función `corr``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d28f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top correlaciones con el target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d267d",
   "metadata": {},
   "source": [
    "# 3. Separación train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b2e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config reproducible\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82847bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa train y test ysando la función adecuada de scikit-learn.\n",
    "# Usa el parámetro random_state=RANDOM_STATE para controlar la aleatoriedad\n",
    "# X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1bec0",
   "metadata": {},
   "source": [
    "La regresión logística se entrena mediante descenso del gradiente, y la escala de las variables afecta la velocidad y estabilidad numérica del entrenamiento. Si las variables tienen órdenes de magnitud distintos, los gradientes también lo tendrán, y el proceso puede converger mal o lentamente.\n",
    "\n",
    "Por este motivo, estandariza los datos usando `StandardScaler` —es decir, restar la media y dividir por la desviación típica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de655975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = \n",
    "#X_train_std = \n",
    "#X_test_std = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906f096",
   "metadata": {},
   "source": [
    "# 4. Entrenar modelos clásicos\n",
    "\n",
    "\n",
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa LogisticRegression para ajustar una regresión logística\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza predicciones sobre test\n",
    "# y_test_hat = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f22e96",
   "metadata": {},
   "source": [
    "Podemos ver no sólo la clase predicha, sino la probabilidad que asigna a cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c29d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa `predict_proba``\n",
    "#y_test_proba = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374874c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de AUC\n",
    "proba_log = log_clf.predict_proba(X_test_std)[:, 1]\n",
    "auc_log = roc_auc_score(y_test, proba_log)\n",
    "print(f\"Logistic Regression AUC: {auc_log}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f34af7d",
   "metadata": {},
   "source": [
    "## Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes usando GaussianNB\n",
    "#nb_clf = \n",
    "#proba_nb = nb_clf.predict_proba(X_test_std)[:,1]\n",
    "#auc_nb = roc_auc_score(y_test, proba_nb)\n",
    "print(f\"GaussianNB AUC: {auc_nb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b855a7",
   "metadata": {},
   "source": [
    "## Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc602f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árbol de decisión (CART) usando DecisionTreeClassifier\n",
    "#tree_clf = \n",
    "\n",
    "proba_tree = tree_clf.predict_proba(X_test_std)[:,1]\n",
    "auc_tree = roc_auc_score(y_test, proba_tree)\n",
    "\n",
    "print(f\"CART AUC: {auc_nb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e15ac4c",
   "metadata": {},
   "source": [
    "# 5. Red Bayesiana \n",
    "\n",
    "Implementa la red bayesiana con `pgmpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db397f23",
   "metadata": {},
   "source": [
    "Seleccionamos un subconjunto de features (top K) para reducir la complejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "\n",
    "mi = mutual_info_classif(X_train, y_train, random_state=42)\n",
    "top_idx = np.argsort(mi)[-K:][::-1]\n",
    "top_features = feature_names[top_idx]\n",
    "print(\"Usando estas variables para la red bayesiana:\", list(top_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c232b",
   "metadata": {},
   "source": [
    "Discretizamos estas features (KBins) usando cuantiles para mantener interpretación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretizar variables usando KBinsDiscretizer\n",
    "kbd = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "X_train_disc = kbd.fit_transform(X_train[:, top_idx])\n",
    "X_test_disc = kbd.transform(X_test[:, top_idx])\n",
    "\n",
    "# Construimos DataFrame discreto para pgmpy\n",
    "cols = [f\"X{i}\" for i in range(K)]\n",
    "df_train_bn = pd.DataFrame(X_train_disc, columns=cols)\n",
    "df_train_bn[\"target\"] = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura de Naïve Bayes: target -> cada feature\n",
    "edges = [(\"target\", f\"X{i}\") for i in range(K)]\n",
    "bn_model = DiscreteBayesianNetwork(edges)\n",
    "\n",
    "# Ajustamos los parámetros por máxima verosimilitud\n",
    "bn_model.fit(df_train_bn, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Inferencia\n",
    "infer = VariableElimination(bn_model)\n",
    "\n",
    "# Predicción de probabilidades para test\n",
    "def bn_predict_proba_row(row_disc):\n",
    "    evidence = {f\"X{i}\": int(row_disc[i]) for i in range(K)}\n",
    "    q = infer.query(variables=[\"target\"], evidence=evidence, show_progress=False)\n",
    "    return float(q.values[1])  # probabilidad de clase 1 (benign)\n",
    "\n",
    "proba_bn = np.array([bn_predict_proba_row(row) for row in X_test_disc])\n",
    "auc_bn = roc_auc_score(y_test, proba_bn)\n",
    "print(f\"AUC - Red bayesiana (Naïve Bayes manual): {auc_bn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8687cb",
   "metadata": {},
   "source": [
    "# 6. Comparación: ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cdb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_log, tpr_log, _ = roc_curve(y_test, proba_log)\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, proba_nb)\n",
    "fpr_tree, tpr_tree, _ = roc_curve(y_test, proba_tree)\n",
    "fpr_bn, tpr_bn, _ = roc_curve(y_test, proba_bn)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_log, tpr_log, label=f'Logistic (AUC={auc_log:.3f})')\n",
    "plt.plot(fpr_nb, tpr_nb, label=f'GaussianNB (AUC={auc_nb:.3f})')\n",
    "plt.plot(fpr_tree, tpr_tree, label=f'DecisionTree (AUC={auc_tree:.3f})')\n",
    "plt.plot(fpr_bn, tpr_bn, label=f'BayesianNet (AUC={auc_bn:.3f})')\n",
    "plt.plot([0,1], [0,1], 'k--', label='Chance')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado resumen en DataFrame\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'model': ['LogisticRegression','GaussianNB','DecisionTree','BayesianNetwork'],\n",
    "    'auc': [auc_log, auc_nb, auc_tree, auc_bn]\n",
    "})\n",
    "print(results.sort_values('auc', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7035229",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlmaster)",
   "language": "python",
   "name": "mlmaster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
